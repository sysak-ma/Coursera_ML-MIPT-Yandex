{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "with open('coursera_sessions_train.txt', 'r') as inf:\n",
    "    for line in inf.readlines():\n",
    "        ids.append([x.strip() for x in line.split(';')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['0,1,2,3,4,5', ''],\n",
       " ['9,10,11,9,11,12,9,11', ''],\n",
       " ['16,17,18,19,20,21', ''],\n",
       " ['24,25,26,27,24', ''],\n",
       " ['34,35,36,34,37,35,36,37,38,39,38,39', ''],\n",
       " ['42', ''],\n",
       " ['47,48,49', ''],\n",
       " ['59,60,61,62,60,63,64,65,66,61,67,68,67', '67,60,63'],\n",
       " ['71,72,73,74', ''],\n",
       " ['76,77,78', '']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([0, 1, 2, 3, 4, 5], []),\n",
       " ([9, 10, 11, 9, 11, 12, 9, 11], []),\n",
       " ([16, 17, 18, 19, 20, 21], []),\n",
       " ([24, 25, 26, 27, 24], []),\n",
       " ([34, 35, 36, 34, 37, 35, 36, 37, 38, 39, 38, 39], []),\n",
       " ([42], []),\n",
       " ([47, 48, 49], []),\n",
       " ([59, 60, 61, 62, 60, 63, 64, 65, 66, 61, 67, 68, 67], [67, 60, 63]),\n",
       " ([71, 72, 73, 74], []),\n",
       " ([76, 77, 78], [])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ids = list(map(lambda x: ([int(a) for a in x[0].split(',')], [int(a) for a in x[1].split(',')] if x[1] != '' else []), ids))\n",
    "train_ids[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "freqs = np.zeros((102807, 2))\n",
    "for viewed, bought in train_ids:\n",
    "    for i in viewed:\n",
    "        freqs[i][0] += 1\n",
    "    for i in bought:\n",
    "        freqs[i][1] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6., 0.],\n",
       "       [6., 0.],\n",
       "       [9., 0.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  more_itertools import unique_everseen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "anses = []\n",
    "for viewed, bought in train_ids:\n",
    "    if len(bought) == 0:\n",
    "        continue\n",
    "    viewed = list(unique_everseen(viewed))\n",
    "    viewed.sort(key = lambda x: -freqs[x][0])\n",
    "    preds = viewed if len(viewed) < 5 else viewed[:5]\n",
    "    P1 = int(preds[0] in bought)\n",
    "    R1 = (preds[0] in bought) / len(bought)\n",
    "    P5 = sum([x in bought for x in preds]) / 5\n",
    "    R5 = sum([x in bought for x in preds]) / len(bought)\n",
    "    anses.append([R1, P1, R5, P5])\n",
    "    \n",
    "anses = np.array(anses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.44263432, 0.51219512, 0.82469182, 0.21252772])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anses.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('viewed_train.txt', 'w') as ouf:\n",
    "    ouf.write(\" \".join([str(np.round(a, 2)) for a in anses.mean(axis=0)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "anses = []\n",
    "for viewed, bought in train_ids:\n",
    "    if len(bought) == 0:\n",
    "        continue\n",
    "    viewed = list(unique_everseen(viewed))\n",
    "    viewed.sort(key = lambda x: -freqs[x][1])\n",
    "    preds = viewed if len(viewed) < 5 else viewed[:5]\n",
    "    P1 = int(preds[0] in bought)\n",
    "    R1 = (preds[0] in bought) / len(bought)\n",
    "    P5 = sum([x in bought for x in preds]) / 5\n",
    "    R5 = sum([x in bought for x in preds]) / len(bought)\n",
    "    anses.append([R1, P1, R5, P5])\n",
    "    \n",
    "anses = np.array(anses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bought_train.txt', 'w') as ouf:\n",
    "    ouf.write(\" \".join([str(np.round(a, 2)) for a in anses.mean(axis=0)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "with open('coursera_sessions_train.txt', 'r') as inf:\n",
    "    for line in inf.readlines():\n",
    "        ids.append([x.strip() for x in line.split(';')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([0, 1, 2, 3, 4, 5], []),\n",
       " ([9, 10, 11, 9, 11, 12, 9, 11], []),\n",
       " ([16, 17, 18, 19, 20, 21], []),\n",
       " ([24, 25, 26, 27, 24], []),\n",
       " ([34, 35, 36, 34, 37, 35, 36, 37, 38, 39, 38, 39], []),\n",
       " ([42], []),\n",
       " ([47, 48, 49], []),\n",
       " ([59, 60, 61, 62, 60, 63, 64, 65, 66, 61, 67, 68, 67], [67, 60, 63]),\n",
       " ([71, 72, 73, 74], []),\n",
       " ([76, 77, 78], [])]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ids = list(map(lambda x: ([int(a) for a in x[0].split(',')], [int(a) for a in x[1].split(',')] if x[1] != '' else []), ids))\n",
    "test_ids[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anses = []\n",
    "for viewed, bought in train_ids:\n",
    "    if len(bought) == 0:\n",
    "        continue\n",
    "    viewed = list(unique_everseen(viewed))\n",
    "    viewed.sort(key = lambda x: -freqs[x][0])\n",
    "    preds = viewed if len(viewed) < 5 else viewed[:5]\n",
    "    P1 = int(preds[0] in bought)\n",
    "    R1 = (preds[0] in bought) / len(bought)\n",
    "    P5 = sum([x in bought for x in preds]) / 5\n",
    "    R5 = sum([x in bought for x in preds]) / len(bought)\n",
    "    anses.append([R1, P1, R5, P5])\n",
    "    \n",
    "anses = np.array(anses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
